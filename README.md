# Self-correcting LLM-controlled Diffusion Models

[![arXiv](https://img.shields.io/badge/arXiv-2311.16090-red)](https://arxiv.org/abs/2311.16090)


**Authors**: [Tsung-Han Wu\*](https://tsunghan-wu.github.io/), [Long Lian\*](https://tonylian.com/), [Joseph E. Gonzalez](https://people.eecs.berkeley.edu/~jegonzal/), [Boyi Li†](https://sites.google.com/site/boyilics/home), [Trevor Darrell†](https://people.eecs.berkeley.edu/~trevor/) at UC Berkeley. 


## TL;DR: The Self-correcting LLM-controlled Diffusion (SLD) Framework features:
1. **Self-correction**: Enhances generative models with LLM-integrated detectors for precise text-to-image alignment.
2. **Unified Generation and Editing**: Excels at both image generation and fine-grained editing.
3. **Universal Compatibility**: Works with ANY image generator, like DALL-E 3, requiring no extra training or data.

![](https://tsunghan-wu.github.io/projects/SLD/teaser.png)

## SLD Framework

![](https://tsunghan-wu.github.io/projects/SLD/main_figure.jpg)

We will release our code soon!
